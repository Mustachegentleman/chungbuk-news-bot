import datetime
import os
import requests
import email.utils
import difflib
from datetime import timedelta

# 1. ì„¤ì •ê°’
NAVER_CLIENT_ID = os.environ.get("NAVER_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_SECRET")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

def get_similarity(str1, str2):
    """ë‘ ë¬¸ì¥ì˜ ê³µë°±ì„ ì œê±°í•˜ê³  ê¸€ì ë°°ì—´ì˜ ìœ ì‚¬ë„ë¥¼ ë°˜í™˜"""
    s1 = str1.replace(" ", "").replace(",", "").replace("'", "").replace('"', "")
    s2 = str2.replace(" ", "").replace(",", "").replace("'", "").replace('"', "")
    return difflib.SequenceMatcher(None, s1, s2).ratio()

def is_recent_news(pub_date_str):
    """ê¸°ì‚¬ ë°œí–‰ì¼ì´ 24ì‹œê°„ ì´ë‚´ì¸ì§€ í™•ì¸"""
    try:
        pub_date = email.utils.parsedate_to_datetime(pub_date_str)
        now = datetime.datetime.now(pub_date.tzinfo)
        return (now - pub_date) < timedelta(days=1)
    except Exception:
        return False

def get_news_score(item):
    """ì–¸ë¡ ì‚¬ ì›ë¬¸ ë§í¬(originallink)ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ ì‹ ë¢°ë„ ì ìˆ˜ ë¶€ì—¬"""
    score = 0
    title = item.get('title', '')
    link = item.get('link', '')
    originallink = item.get('originallink', '') # ì–¸ë¡ ì‚¬ ì‹¤ì œ ì£¼ì†Œ
    
    # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ í”Œë«í¼ ë§í¬ ìš°ì„  (+10ì )
    if "n.news.naver.com" in link:
        score += 10
        
    # 2. ë©”ì´ì € í†µì‹ ì‚¬ ë° ì£¼ìš” ë°©ì†¡ì‚¬ ì›ë¬¸ ë„ë©”ì¸ ê°€ì  (+5ì )
    reputable_domains = [
        "yna.co.kr", "newsis.com", "news1.kr", "nocutnews.co.kr", 
        "kbs.co.kr", "mbc.com", "sbs.co.kr", "ytn.co.kr"
    ]
    if any(domain in originallink.lower() for domain in reputable_domains):
        score += 5
        
    # 3. ì¶©ë¶ ì§€ì—­ ìœ ë ¥ì§€ ë„ë©”ì¸ ê°€ì  (+5ì )
    local_domains = [
        "inews365", "ccdailynews", "jbnews", "cctoday", "chungbuk"
    ]
    if any(domain in originallink.lower() for domain in local_domains):
        score += 5
        
    # 4. ì œëª©ì´ ê¸¸ìˆ˜ë¡ ìƒì„¸ ì •ë³´ í¬í•¨ í™•ë¥  ë†’ìŒ
    score += len(title) * 0.1
    
    return score

def is_valid_news(title):
    """ë…¸ì´ì¦ˆ ê¸°ì‚¬ í•„í„°ë§"""
    blacklist = [
        "ì§ì—…êµ°ì¸ì´ì•¼ê¸°", "ì¹¼ëŸ¼", "ì¸ì‚¬", "ë¶€ê³ ", "ìš´ì„¸", "ê²Œì‹œíŒ", "ë™ì •", 
        "ê²€ê±°", "êµ¬ì†", "ì‚´ì¸", "í­í–‰", "ì‚¬ê¸°", "ë§ˆì•½", "ì„±ë²”ì£„", "íš¡ë ¹", "ì ˆë„",
        "ì••ìˆ˜ìˆ˜ìƒ‰", "ì¬íŒ", "ë²•ì›", "ê²€ì°°", "ê²½ì°°ê´€", "ìŠµê²©", "í™”ì¬", "ë¶ˆ", "ê³µì±„", "ì±„ìš©"
    ]
    for word in blacklist:
        if word in title:
            return False

    traffic_keywords = [
        "ë„ë¡œ", "êµí†µ", "ì‚¬ê³ ", "í†µì œ", "ê³µì‚¬", "ì •ì²´", "ë‹¨ì†", 
        "ê°œí†µ", "ìš°íšŒ", "ì°¨ëŸ‰", "ì‹ í˜¸", "ìš´ì „", "ë©´í—ˆ", "í•˜ì´íŒ¨ìŠ¤", "í„°ë„"
    ]
    return any(word in title for word in traffic_keywords)

def fetch_traffic_news():
    search_queries = ["ì¶©ë¶ êµí†µ ì‚¬ê³ ", "ì²­ì£¼ ë„ë¡œ í†µì œ", "ì¶©ë¶ ë„ë¡œê³µì‚¬", "ì¶©ë¶ ì‹¤ì‹œê°„ êµí†µ", "ì¶©ë¶ êµí†µ ì •ì²´"]
    raw_news = []

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }

    # 1. 1ì°¨ ìˆ˜ì§‘ (ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ ëª¨ë‘ ëª¨ìœ¼ê¸°)
    for query in search_queries:
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=20&sort=sim"
        res = requests.get(url, headers=headers)

        if res.status_code == 200:
            items = res.json().get("items", [])
            for item in items:
                title = item["title"].replace("<b>", "").replace("</b>", "").replace("&quot;", '"').replace("&apos;", "'")
                pub_date = item.get("pubDate", "")

                if is_recent_news(pub_date) and is_valid_news(title):
                    # ì ìˆ˜ ê³„ì‚° ì‹œ item ì „ì²´ë¥¼ ë„˜ê²¨ originallinkê¹Œì§€ ê²€ì‚¬í•˜ë„ë¡ ìˆ˜ì •
                    item['title'] = title 
                    news_obj = {
                        "title": title,
                        "link": item["link"],
                        "score": get_news_score(item) 
                    }
                    raw_news.append(news_obj)

    # 2. [ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”] ê¸°ì‚¬ë¥¼ ì ìˆ˜(ì‹ ë¢°ë„)ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤.
    raw_news.sort(key=lambda x: x["score"], reverse=True)

    # 3. 1ë“±ë¶€í„° ì¥ë°”êµ¬ë‹ˆì— ë‹´ìœ¼ë©´ì„œ, ì¤‘ë³µë˜ëŠ” í•˜ìœ„ ê¸°ì‚¬ë“¤ì€ ê°€ì°¨ ì—†ì´ ë²„ë¦½ë‹ˆë‹¤.
    unique_news = []
    for news in raw_news:
        is_duplicate = False
        for existing in unique_news:
            # ì´ë¯¸ ì¥ë°”êµ¬ë‹ˆì— ìˆëŠ” ìƒìœ„ ì ìˆ˜ ê¸°ì‚¬ì™€ 45% ì´ìƒ ì¼ì¹˜í•˜ë©´ ë²„ë¦¼
            if get_similarity(news["title"], existing["title"]) > 0.45:
                is_duplicate = True
                break
                
        if not is_duplicate:
            unique_news.append(news)

    return unique_news

def send_telegram(news_list):
    now = datetime.datetime.now()
    date_str = now.strftime("%Yë…„ %mì›” %dì¼")

    if not news_list:
        message = f"ğŸ“¢ {date_str}\nì˜¤ëŠ˜ ì¶©ë¶ ì§€ì—­ì˜ ì‹ ê·œ êµí†µ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    else:
        message = f"ğŸš— [{date_str} ì¶©ë¶ êµí†µ ë‰´ìŠ¤ ë¸Œë¦¬í•‘]\n\n"
        for i, news in enumerate(news_list[:10], 1):
            message += f"{i}. {news['title']}\nğŸ”— {news['link']}\n\n"
        message += "ğŸ’¡ 24ì‹œê°„ ì´ë‚´ ìµœì‹  ë‰´ìŠ¤ ì¤‘ ì‹ ë¢°ë„ê°€ ë†’ì€ ê¸°ì‚¬ë¥¼ ì—„ì„ í–ˆìŠµë‹ˆë‹¤."

    send_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": message, "disable_web_page_preview": True}
    requests.post(send_url, data=payload)

if __name__ == "__main__":
    try:
        news_data = fetch_traffic_news()
        send_telegram(news_data)
        print(f"[{datetime.datetime.now()}] ì „ì†¡ ì„±ê³µ: {len(news_data)}ê±´")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")